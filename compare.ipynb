{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0ffe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.64%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"answer_key.txt\", \"r\") as answer_file:\n",
    "    answer_lines = answer_file.readlines()\n",
    "\n",
    "with open(\"predict_31Oct_1.txt\", \"r\") as predict_file:\n",
    "    predict_lines = predict_file.readlines()\n",
    "\n",
    "if len(answer_lines) != len(predict_lines):\n",
    "    print(\"The number of lines in answer_key.txt and predict.txt does not match.\")\n",
    "else:\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(answer_lines)\n",
    "\n",
    "    for i in range(total_predictions):\n",
    "        answer_label = answer_lines[i].strip().split(\"\\t\")[1]\n",
    "        predict_label = predict_lines[i].strip().split(\"\\t\")[1]\n",
    "\n",
    "        if answer_label == predict_label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8ef386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[196   0   0  12   0  74   6   0   4   0]\n",
      " [  4 131   4  34   0  56   0   1  28   0]\n",
      " [  0   1 251  18   1  37   0   2  18   0]\n",
      " [ 32   9  14 103  35 178  12  23  45   3]\n",
      " [  1   0   0  23 160  46   0   0   2   1]\n",
      " [  1   1   1   7   9 283   0   0  10   0]\n",
      " [  3   1   0   3   1  64 118   1   1   0]\n",
      " [  0   1   1  11   0 100   0 144   4   0]\n",
      " [  2   2   2  14   0  45   0   6 160   0]\n",
      " [  2   1   4  24   4  53   0   0  48  20]]\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Entity-Destination       0.91      0.77      0.83       328\n",
      "     Entity-Origin       0.30      0.91      0.45       312\n",
      "      Cause-Effect       0.87      0.61      0.72       192\n",
      "             Other       0.81      0.67      0.74       292\n",
      " Member-Collection       0.89      0.51      0.65       258\n",
      "   Component-Whole       0.83      0.13      0.22       156\n",
      " Content-Container       0.76      0.69      0.72       233\n",
      "     Message-Topic       0.81      0.55      0.66       261\n",
      "  Product-Producer       0.41      0.23      0.29       454\n",
      " Instrument-Agency       0.50      0.69      0.58       231\n",
      "\n",
      "          accuracy                           0.58      2717\n",
      "         macro avg       0.71      0.58      0.59      2717\n",
      "      weighted avg       0.68      0.58      0.58      2717\n",
      "\n",
      "Accuracy: 57.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"answer_key.txt\", \"r\") as answer_file:\n",
    "    answer_lines = answer_file.readlines()\n",
    "\n",
    "with open(\"predict_31Oct_1.txt\", \"r\") as predict_file:\n",
    "    predict_lines = predict_file.readlines()\n",
    "\n",
    "# Extract the true labels and predicted labels\n",
    "true_labels = [line.strip().split(\"\\t\")[1] for line in answer_lines]\n",
    "predicted_labels = [line.strip().split(\"\\t\")[1] for line in predict_lines]\n",
    "\n",
    "\n",
    "unique_labels = list(set(true_labels + predicted_labels))\n",
    "\n",
    "confusion = confusion_matrix(true_labels, predicted_labels, labels=unique_labels)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "\n",
    "class_report = classification_report(true_labels, predicted_labels, target_names=unique_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3a859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
