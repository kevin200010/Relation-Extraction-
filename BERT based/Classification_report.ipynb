{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "input_file_path = '/content/drive/MyDrive/Colab Notebooks/results/output_base.txt'\n",
        "\n",
        "\n",
        "output_file_path = '/content/drive/MyDrive/Colab Notebooks/results/output_base2.txt'\n",
        "\n",
        "with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n",
        "\n",
        "    for line in input_file:\n",
        "\n",
        "        modified_line = re.sub(r'\\(e[12],e[12]\\)', '', line)\n",
        "\n",
        "\n",
        "        output_file.write(modified_line)"
      ],
      "metadata": {
        "id": "H4-b98KovlVp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/data/answer_key.txt\", \"r\") as answer_file:\n",
        "    answer_lines = answer_file.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/results/output_base2.txt\", \"r\") as predict_file:\n",
        "    predict_lines = predict_file.readlines()\n",
        "\n",
        "if len(answer_lines) != len(predict_lines):\n",
        "    print(\"The number of lines in answer_key.txt and predict.txt does not match.\")\n",
        "else:\n",
        "    correct_predictions = 0\n",
        "    total_predictions = len(answer_lines)\n",
        "\n",
        "    for i in range(total_predictions):\n",
        "        answer_label = answer_lines[i].strip().split(\"\\t\")[1]\n",
        "        predict_label = predict_lines[i].strip().split(\"\\t\")[1]\n",
        "\n",
        "        if answer_label == predict_label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = (correct_predictions / total_predictions) * 100\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7CS4wpRvl-o",
        "outputId": "c3aee3d1-0c8b-4676-934b-0e5dcedf15ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/data/answer_key.txt\", \"r\") as answer_file:\n",
        "    answer_lines = answer_file.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/results/output_base2.txt\", \"r\") as predict_file:\n",
        "    predict_lines = predict_file.readlines()\n",
        "\n",
        "\n",
        "true_labels = [line.strip().split(\"\\t\")[1] for line in answer_lines]\n",
        "predicted_labels = [line.strip().split(\"\\t\")[1] for line in predict_lines]\n",
        "\n",
        "unique_labels = list(set(true_labels + predicted_labels))\n",
        "\n",
        "confusion = confusion_matrix(true_labels, predicted_labels, labels=unique_labels)\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=unique_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8zdLI59vmZe",
        "outputId": "b5339a2b-7846-4655-b1ba-a514d7e6a6a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[304   2   1   1   0   0   0   0  20   0]\n",
            " [  8 203   1   9   0   0   0   0  36   1]\n",
            " [  0   0 242   0   0   1   1   0  17   0]\n",
            " [  2   1   1 191   4   0   0   0  32   0]\n",
            " [  1   0   0   7 102   0   5   0  39   2]\n",
            " [  0   1   0   0   0 210   4   0  17   1]\n",
            " [  0   1   4   1   4  12 245   1  44   0]\n",
            " [  0   0   0   0   0   0   0 162  24   6]\n",
            " [ 14  11  21  14   9  25  19   9 317  15]\n",
            " [  0   0   0   0   0   0   1   3  11 277]]\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      Cause-Effect       0.92      0.93      0.93       328\n",
            "     Entity-Origin       0.89      0.79      0.83       312\n",
            "     Message-Topic       0.93      0.84      0.88       192\n",
            "  Product-Producer       0.92      0.95      0.93       292\n",
            " Instrument-Agency       0.93      0.79      0.85       258\n",
            " Member-Collection       0.86      0.65      0.74       156\n",
            "   Component-Whole       0.85      0.90      0.87       233\n",
            " Content-Container       0.90      0.93      0.91       261\n",
            "             Other       0.57      0.70      0.63       454\n",
            "Entity-Destination       0.86      0.83      0.84       231\n",
            "\n",
            "          accuracy                           0.83      2717\n",
            "         macro avg       0.86      0.83      0.84      2717\n",
            "      weighted avg       0.84      0.83      0.83      2717\n",
            "\n",
            "Accuracy: 82.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFy-7_h4vmc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlliOfeDvmmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uuo-bs4jbvyd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "input_file_path = '/content/drive/MyDrive/Colab Notebooks/results/output_large.txt'\n",
        "\n",
        "\n",
        "output_file_path = '/content/drive/MyDrive/Colab Notebooks/results/output_large2.txt'\n",
        "\n",
        "with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n",
        "\n",
        "    for line in input_file:\n",
        "\n",
        "        modified_line = re.sub(r'\\(e[12],e[12]\\)', '', line)\n",
        "\n",
        "\n",
        "        output_file.write(modified_line)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/data/answer_key.txt\", \"r\") as answer_file:\n",
        "    answer_lines = answer_file.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/results/output_large2.txt\", \"r\") as predict_file:\n",
        "    predict_lines = predict_file.readlines()\n",
        "\n",
        "if len(answer_lines) != len(predict_lines):\n",
        "    print(\"The number of lines in answer_key.txt and predict.txt does not match.\")\n",
        "else:\n",
        "    correct_predictions = 0\n",
        "    total_predictions = len(answer_lines)\n",
        "\n",
        "    for i in range(total_predictions):\n",
        "        answer_label = answer_lines[i].strip().split(\"\\t\")[1]\n",
        "        predict_label = predict_lines[i].strip().split(\"\\t\")[1]\n",
        "\n",
        "        if answer_label == predict_label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = (correct_predictions / total_predictions) * 100\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY5FjXq4cPrv",
        "outputId": "7290c27c-b9d7-4fdd-bf15-0cbe7fd87ac4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/data/answer_key.txt\", \"r\") as answer_file:\n",
        "    answer_lines = answer_file.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/results/output_large2.txt\", \"r\") as predict_file:\n",
        "    predict_lines = predict_file.readlines()\n",
        "\n",
        "\n",
        "true_labels = [line.strip().split(\"\\t\")[1] for line in answer_lines]\n",
        "predicted_labels = [line.strip().split(\"\\t\")[1] for line in predict_lines]\n",
        "\n",
        "unique_labels = list(set(true_labels + predicted_labels))\n",
        "\n",
        "confusion = confusion_matrix(true_labels, predicted_labels, labels=unique_labels)\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=unique_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8wTioB5cT5C",
        "outputId": "f3cee133-4970-4c8d-dd4b-da22124343e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[310   2   1   2   0   0   0   0  13   0]\n",
            " [  6 225   0   5   0   0   2   0  18   2]\n",
            " [  0   0 232   0   0   1  11   0  17   0]\n",
            " [  3   3   2 195   6   0   1   0  21   0]\n",
            " [  1   0   0   6 112   0   4   0  33   0]\n",
            " [  0   1   1   0   1 197   9   0  23   1]\n",
            " [  0   0   3   2   4   4 276   2  21   0]\n",
            " [  0   0   1   0   0   0   7 174   5   5]\n",
            " [ 20  13  26  16   9  26  28  14 286  16]\n",
            " [  0   0   0   0   0   0   0   4  19 269]]\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      Cause-Effect       0.91      0.95      0.93       328\n",
            "     Entity-Origin       0.82      0.88      0.85       312\n",
            "     Message-Topic       0.90      0.91      0.90       192\n",
            "  Product-Producer       0.92      0.92      0.92       292\n",
            " Instrument-Agency       0.92      0.87      0.90       258\n",
            " Member-Collection       0.85      0.72      0.78       156\n",
            "   Component-Whole       0.86      0.85      0.85       233\n",
            " Content-Container       0.87      0.89      0.88       261\n",
            "             Other       0.63      0.63      0.63       454\n",
            "Entity-Destination       0.86      0.84      0.85       231\n",
            "\n",
            "          accuracy                           0.84      2717\n",
            "         macro avg       0.85      0.85      0.85      2717\n",
            "      weighted avg       0.84      0.84      0.84      2717\n",
            "\n",
            "Accuracy: 83.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wR_9tUkOcY5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usIz3ofgvZYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}